import pandas as pd
import numpy as np
import os
import streamlit as st
from datetime import datetime

# ========== CONFIGURA√á√ïES INICIAIS ==========
st.set_page_config(page_title="üìä Painel de Repasses e Vendas", layout="wide")

# T√≠tulo da aplica√ß√£o
st.title("üìä Painel de Repasses e Vendas")
st.markdown("Este painel permite filtrar, pesquisar e verificar diverg√™ncias nos repasses de vendas.")

# ========== MAPA DE C√ìDIGOS DE ERRO ==========
ERRO_MAP = {
    "Leitura_Erro": 1001,          # Erro ao ler o arquivo
    "Conversao_Tipo": 1002,        # Erro na convers√£o de tipo de dados
    "Valor_Nulo": 1003,            # Valor nulo inesperado
    "Divergencia": 1004,           # Diverg√™ncia encontrada durante a concilia√ß√£o
    "Falha_Consolidacao": 1005     # Falha na consolida√ß√£o dos dados
}

# Inicializar lista para coletar erros
if 'lista_erros' not in st.session_state:
    st.session_state.lista_erros = []

# Fun√ß√£o para registrar erros
def registrar_erro(arquivo, tipo_erro, mensagem):
    novo_log = {
        "Timestamp": datetime.now(),
        "Arquivo": arquivo,
        "Codigo_Erro": ERRO_MAP.get(tipo_erro, 9999),
        "Mensagem_Erro": mensagem
    }
    st.session_state.lista_erros.append(novo_log)

# ========== FUN√á√ïES DE CONVERS√ÉO ==========
def convert_to_float(x):
    x = str(x).strip()
    if '.' in x and ',' in x:
        # Assume que '.' √© separador de milhares e ',' √© decimal
        x = x.replace('.', '').replace(',', '.')
    elif ',' in x:
        # Assume que ',' √© separador decimal
        x = x.replace(',', '.')
    # Se apenas '.' est√° presente, assume que √© separador decimal
    try:
        return float(x)
    except ValueError:
        # Retorna NaN se a convers√£o falhar
        return np.nan

def convert_to_date(x, dayfirst=True):
    """
    Converte uma data para o formato AAAAMMDD.

    Par√¢metros:
    - x: valor da data.
    - dayfirst: booleano que indica se o primeiro elemento √© o dia.

    Retorna:
    - String no formato AAAAMMDD ou NaN se a convers√£o falhar.
    """
    if pd.isnull(x):
        return np.nan
    try:
        # Tenta converter a string para datetime com a configura√ß√£o de dayfirst
        parsed_date = pd.to_datetime(x, dayfirst=dayfirst, errors='coerce')
        if pd.isnull(parsed_date):
            return np.nan
        return parsed_date.strftime('%Y%m%d')  # Formato AAAAMMDD
    except Exception as e:
        registrar_erro("Conversao_Data", "Conversao_Tipo", f"Erro ao converter a data {x}: {e}")
        return np.nan

# ========== FUN√á√ïES DE PROCESSAMENTO DE DADOS ==========
def processar_vendas(file_path):
    try:
        df = pd.read_excel(
            file_path,
            usecols=[
                "C√ìDIGO PEDIDO", 
                "DATA PEDIDO", 
                "MARKETPLACE", 
                "STATUS", 
                "FRETE DO LOJISTA", 
                "FRETE", 
                "VALOR TOTAL DOS PRODUTOS", 
                "TOTAL DO PEDIDO"
            ]
        )
        
        # Garantir que as colunas categ√≥ricas sejam do tipo string
        df["C√ìDIGO PEDIDO"] = df["C√ìDIGO PEDIDO"].astype(str)
        df["MARKETPLACE"] = df["MARKETPLACE"].astype(str)
        df["STATUS"] = df["STATUS"].astype(str)
        
        # Aplicando a fun√ß√£o de convers√£o personalizada para n√∫meros
        df["FRETE"] = df["FRETE"].apply(convert_to_float)
        df["FRETE DO LOJISTA"] = df["FRETE DO LOJISTA"].apply(convert_to_float)
        df["VALOR TOTAL DOS PRODUTOS"] = df["VALOR TOTAL DOS PRODUTOS"].apply(convert_to_float)
        df["TOTAL DO PEDIDO"] = df["TOTAL DO PEDIDO"].apply(convert_to_float)
        
        # Criando a coluna "FRETE TOTAL" somando "FRETE" e "FRETE DO LOJISTA"
        df["FRETE TOTAL"] = df["FRETE"].fillna(0) + df["FRETE DO LOJISTA"].fillna(0)
        
        # Remover as colunas originais de frete
        df = df.drop(columns=["FRETE", "FRETE DO LOJISTA"])
        
        # Aplicando a fun√ß√£o de convers√£o para datas com dayfirst=True
        df["DATA PEDIDO"] = df["DATA PEDIDO"].apply(lambda x: convert_to_date(x, dayfirst=True))
        
        # Criando a coluna "VALOR ESPERADO" = "TOTAL DO PEDIDO" - "FRETE TOTAL"
        df["VALOR ESPERADO"] = df["TOTAL DO PEDIDO"] - df["FRETE TOTAL"]
        
        # Remover duplicatas em Vendas: manter apenas uma ocorr√™ncia por "C√ìDIGO PEDIDO" e "VALOR ESPERADO"
        df = df.drop_duplicates(subset=["C√ìDIGO PEDIDO", "VALOR ESPERADO"], keep='first')
        
        return df
    except Exception as e:
        registrar_erro(os.path.basename(file_path), "Leitura_Erro", str(e))
        return pd.DataFrame()

def processar_centauro(file_path):
    try:
        df = pd.read_csv(
            file_path, 
            sep=';', 
            usecols=["Pedido", "DataPedido", "StatusAtendimento", "ValorPedido", "ValorFrete", "Comissao", "RepasseLiquido"]
        )
        
        # Renomeando as colunas para padronizar com 'vendas'
        df.rename(columns={
            "Pedido": "C√ìDIGO PEDIDO",
            "DataPedido": "DATA PEDIDO",
            "StatusAtendimento": "STATUS",
            "ValorPedido": "TOTAL DO PEDIDO",
            "ValorFrete": "FRETE TOTAL",
            "Comissao": "COMISSAO",
            "RepasseLiquido": "VALOR TOTAL DOS PRODUTOS"
        }, inplace=True)
        
        # Garantir que as colunas categ√≥ricas sejam do tipo string
        df["C√ìDIGO PEDIDO"] = df["C√ìDIGO PEDIDO"].astype(str)
        df["STATUS"] = df["STATUS"].astype(str)
        
        # Aplicando a fun√ß√£o de convers√£o para datas com dayfirst=False
        df["DATA PEDIDO"] = df["DATA PEDIDO"].apply(lambda x: convert_to_date(x, dayfirst=False))
        
        # Aplicando a fun√ß√£o de convers√£o personalizada para n√∫meros
        numeric_cols = ["VALOR TOTAL DOS PRODUTOS", "FRETE TOTAL", "COMISSAO", "TOTAL DO PEDIDO"]
        for col in numeric_cols:
            df[col] = df[col].apply(convert_to_float)
        
        # Adicionar coluna "Tipo" com base no valor
        df["Tipo"] = df["VALOR TOTAL DOS PRODUTOS"].apply(lambda x: "Extorno" if x < 0 else "Produto")
        
        # Garantir que 'STATUS' exista
        if 'STATUS' not in df.columns:
            df['STATUS'] = "N√£o informado"
        else:
            df['STATUS'] = df['STATUS'].fillna("N√£o informado")
        
        return df
    except Exception as e:
        registrar_erro(os.path.basename(file_path), "Leitura_Erro", str(e))
        return pd.DataFrame()

def processar_netshoes_ns2(file_path):
    try:
        df = pd.read_excel(
            file_path, 
            skiprows=7, 
            usecols=[
                "Nr Pedido Netshoes", 
                "Data da Compra", 
                "Valor Total Frete Lojista", 
                "Valor Total Produtos Lojista", 
                "Valor Total Pedido Lojista", 
                "Tipo do Pedido", 
                "Tarifa fixa por pedido"
            ]
        )
        
        # Renomeando as colunas para padronizar com 'vendas'
        df.rename(columns={
            "Nr Pedido Netshoes": "C√ìDIGO PEDIDO",
            "Valor Total Pedido Lojista": "TOTAL DO PEDIDO",
            "Data da Compra": "DATA PEDIDO",
            "Valor Total Frete Lojista": "FRETE TOTAL",
            "Valor Total Produtos Lojista": "VALOR TOTAL DOS PRODUTOS",
            "Tipo do Pedido": "STATUS",
            "Tarifa fixa por pedido": "FRETE FIXO"
        }, inplace=True)
        
        # Garantir que 'STATUS' exista
        if 'STATUS' not in df.columns:
            df['STATUS'] = "N√£o informado"
        else:
            df['STATUS'] = df['STATUS'].fillna("N√£o informado")
        
        # Aplicando a fun√ß√£o de convers√£o personalizada para n√∫meros
        monetary_columns = ["VALOR TOTAL DOS PRODUTOS", "FRETE TOTAL", "COMISSAO", "TOTAL DO PEDIDO", "FRETE FIXO"]
        for col in monetary_columns:
            if col in df.columns:
                df[col] = df[col].apply(convert_to_float)
        
        # Adicionar "FRETE FIXO" √† "COMISSAO"
        if "COMISSAO" in df.columns and "FRETE FIXO" in df.columns:
            df["COMISSAO"] += df["FRETE FIXO"].fillna(0)
        
        # Remover a coluna "FRETE FIXO"
        if "FRETE FIXO" in df.columns:
            df = df.drop(columns=["FRETE FIXO"])
        
        # Adicionar coluna "Tipo" com base no valor
        df["Tipo"] = df["VALOR TOTAL DOS PRODUTOS"].apply(lambda x: "Extorno" if x < 0 else "Produto")
        
        return df
    except Exception as e:
        registrar_erro(os.path.basename(file_path), "Leitura_Erro", str(e))
        return pd.DataFrame()

def processar_netshoes_magalu(file_path):
    try:
        df = pd.read_excel(
            file_path,
            usecols=[
                "ID do pedido Netshoes", 
                "Data do pedido", 
                "Valor bruto do pedido", 
                "Valor Servi√ßos de Marketplace", 
                "Tarifa fixa por pedido"
            ]
        )
        
        # Renomeando as colunas para padronizar com 'vendas'
        df.rename(columns={
            "ID do pedido Netshoes": "C√ìDIGO PEDIDO",
            "Data do pedido": "DATA PEDIDO",
            "Valor bruto do pedido": "VALOR TOTAL DOS PRODUTOS",
            "Valor Servi√ßos de Marketplace": "COMISSAO",
            "Tarifa fixa por pedido": "FRETE FIXO"
        }, inplace=True)
        
        # Garantir que as colunas categ√≥ricas sejam do tipo string
        df["C√ìDIGO PEDIDO"] = df["C√ìDIGO PEDIDO"].astype(str)
        
        # Aplicando a fun√ß√£o de convers√£o personalizada para n√∫meros
        monetary_columns = ["VALOR TOTAL DOS PRODUTOS", "FRETE TOTAL", "COMISSAO", "FRETE FIXO"]
        for col in monetary_columns:
            if col in df.columns:
                df[col] = df[col].apply(convert_to_float)
        
        # Calculando a coluna "TOTAL DO PEDIDO"
        if "VALOR TOTAL DOS PRODUTOS" in df.columns and "FRETE TOTAL" not in df.columns:
            df["FRETE TOTAL"] = 0.0  # Assume que n√£o h√° frete total se n√£o estiver presente
        if "TOTAL DO PEDIDO" not in df.columns:
            df["TOTAL DO PEDIDO"] = df["VALOR TOTAL DOS PRODUTOS"] + df["FRETE TOTAL"]
        
        # Adicionar "FRETE FIXO" √† "COMISSAO"
        if "COMISSAO" in df.columns and "FRETE FIXO" in df.columns:
            df["COMISSAO"] += df["FRETE FIXO"].fillna(0)
        
        # Remover a coluna "FRETE FIXO"
        if "FRETE FIXO" in df.columns:
            df = df.drop(columns=["FRETE FIXO"])
        
        # Aplicando a fun√ß√£o de convers√£o para datas com dayfirst=True
        df["DATA PEDIDO"] = df["DATA PEDIDO"].apply(lambda x: convert_to_date(x, dayfirst=True))
        
        # Adicionar coluna "Tipo" com base no valor
        df["Tipo"] = df["VALOR TOTAL DOS PRODUTOS"].apply(lambda x: "Extorno" if x < 0 else "Produto")
        
        # Garantir que 'STATUS' exista
        if 'STATUS' not in df.columns:
            df['STATUS'] = "N√£o informado"
        else:
            df['STATUS'] = df['STATUS'].fillna("N√£o informado")
        
        return df
    except Exception as e:
        registrar_erro(os.path.basename(file_path), "Leitura_Erro", str(e))
        return pd.DataFrame()

# ========== FUN√á√ÉO DE CONCILIACAO ==========
def conciliar_dados(vendas, centauro, netshoes_ns2, netshoes_magalu):
    """
    Concilia os dados das diferentes fontes.

    Par√¢metros:
    - vendas: DataFrame de Vendas
    - centauro: DataFrame de Centauro
    - netshoes_ns2: DataFrame de Netshoes NS2
    - netshoes_magalu: DataFrame de Netshoes Magalu

    Retorna:
    - DataFrame consolidado com concilia√ß√£o e sinaliza√ß√£o de diverg√™ncias
    """
    # Criar um dicion√°rio para armazenar os dados por "C√ìDIGO PEDIDO"
    pedidos_dict = {}

    # Processar Vendas para obter "Valor Esperado"
    vendas_grouped = vendas.groupby("C√ìDIGO PEDIDO").agg({
        "DATA PEDIDO": 'first',
        "MARKETPLACE": lambda x: ', '.join(x.dropna().unique()),
        "STATUS": lambda x: ', '.join(x.dropna().unique()),
        "VALOR ESPERADO": 'sum'
    }).reset_index()

    for _, row in vendas_grouped.iterrows():
        codigo = row["C√ìDIGO PEDIDO"]
        pedidos_dict[codigo] = {
            "C√ìDIGO PEDIDO": codigo,
            "DATA PEDIDO": row["DATA PEDIDO"],
            "MARKETPLACE": row["MARKETPLACE"],
            "STATUS": row["STATUS"],
            "Valor Esperado": row["VALOR ESPERADO"],
            "Valor Recebido": 0.0,  # Soma dos Produtos
            "Extorno": 0.0,         # Soma dos Extornos
            "Diferen√ßa": 0.0,
            "Conciliado": "OK",
            "Poss√≠vel Motivo": "Nenhum",
            "Erro de Valor": "‚úÖ",
            "Outro Erro": "‚úÖ"
        }

    # Fun√ß√£o para acumular valores recebidos e extornos
    def acumular_recebido_extorno(df, fonte):
        for _, row in df.iterrows():
            codigo = row["C√ìDIGO PEDIDO"]
            valor = row.get("VALOR TOTAL DOS PRODUTOS", 0.0)
            tipo = row.get("Tipo", "Produto")
            if pd.isna(valor):
                valor = 0.0
            valor = float(valor)
            if codigo in pedidos_dict:
                if tipo == "Produto":
                    pedidos_dict[codigo]["Valor Recebido"] += valor
                elif tipo == "Extorno":
                    pedidos_dict[codigo]["Extorno"] += valor
            else:
                # Caso o pedido n√£o esteja em vendas, adiciona com Valor Esperado = 0
                pedidos_dict[codigo] = {
                    "C√ìDIGO PEDIDO": codigo,
                    "DATA PEDIDO": row.get("DATA PEDIDO", np.nan),
                    "MARKETPLACE": row.get("MARKETPLACE", ""),
                    "STATUS": row.get("STATUS", "N√£o informado"),
                    "Valor Esperado": 0.0,
                    "Valor Recebido": valor if tipo == "Produto" else 0.0,
                    "Extorno": valor if tipo == "Extorno" else 0.0,
                    "Diferen√ßa": 0.0,
                    "Conciliado": "Divergente",
                    "Poss√≠vel Motivo": "Pedido n√£o encontrado na planilha de vendas.",
                    "Erro de Valor": "‚ùå",
                    "Outro Erro": "‚ùå"
                }

    # Acumular valores de Centauro
    acumular_recebido_extorno(centauro, "Centauro")

    # Acumular valores de Netshoes NS2
    acumular_recebido_extorno(netshoes_ns2, "Netshoes NS2")

    # Acumular valores de Netshoes Magalu
    acumular_recebido_extorno(netshoes_magalu, "Netshoes Magalu")

    # Agora, calcular a diferen√ßa e conciliar
    for codigo, dados in pedidos_dict.items():
        dados["Diferen√ßa"] = dados["Valor Recebido"] - dados["Valor Esperado"]
        
        # Verificar Erro de Valor
        if abs(dados["Diferen√ßa"]) >= 0.01:
            dados["Erro de Valor"] = "‚ùå"
            dados["Conciliado"] = "Divergente"
            dados["Poss√≠vel Motivo"] = "Verificar discrep√¢ncias no valor do pedido."
        else:
            dados["Erro de Valor"] = "‚úÖ"
        
        # Verificar se Extorno est√° balanceado
        if abs(dados["Extorno"]) >= 0.01:
            # Extorno deve balancear as devolu√ß√µes
            # Aqui, voc√™ pode adicionar l√≥gica adicional se houver requisitos espec√≠ficos
            dados["Outro Erro"] = "‚ùå"
            dados["Conciliado"] = "Divergente"
            if dados["Poss√≠vel Motivo"] == "Nenhum":
                dados["Poss√≠vel Motivo"] = "Verificar extornos do pedido."
        else:
            dados["Outro Erro"] = "‚úÖ"

    # Converter o dicion√°rio para DataFrame
    final_df = pd.DataFrame.from_dict(pedidos_dict, orient='index').reset_index(drop=True)

    return final_df

# ========== FUN√á√ÉO DE CONCILIACAO FINAL ==========
def conciliar_e_calcular(vendas, centauro, netshoes_ns2, netshoes_magalu):
    final_df = conciliar_dados(vendas, centauro, netshoes_ns2, netshoes_magalu)
    return final_df

# ========== FUN√á√ÉO DE CARREGAMENTO DOS ARQUIVOS ==========
@st.cache_data
def carregar_dados_locais():
    """
    Carrega os dados das fontes locais.

    Retorna:
    - DataFrames combinados de cada fonte
    """
    base_dir = os.getcwd()  # Diret√≥rio atual

    folder_path_vendas = os.path.join(base_dir, 'Vendas')
    folder_path_centauro = os.path.join(base_dir, 'Repasse Centauro')
    folder_path_netshoes_ns2 = os.path.join(base_dir, 'Repasse Netshoes', 'NS2')
    folder_path_netshoes_magalu = os.path.join(base_dir, 'Repasse Netshoes', 'Magalu Pagamentos')

    # Verificar se as pastas existem
    for path in [folder_path_vendas, folder_path_centauro, folder_path_netshoes_ns2, folder_path_netshoes_magalu]:
        if not os.path.exists(path):
            registrar_erro(path, "Leitura_Erro", f"Pasta n√£o encontrada: {path}")

    # Listar arquivos em cada pasta
    files_vendas = [os.path.join(folder_path_vendas, f) for f in os.listdir(folder_path_vendas) if f.endswith(('.xlsx', '.xls'))] if os.path.exists(folder_path_vendas) else []
    files_centauro = [os.path.join(folder_path_centauro, f) for f in os.listdir(folder_path_centauro) if f.endswith('.csv')] if os.path.exists(folder_path_centauro) else []
    files_netshoes_ns2 = [os.path.join(folder_path_netshoes_ns2, f) for f in os.listdir(folder_path_netshoes_ns2) if f.endswith(('.xlsx', '.xls'))] if os.path.exists(folder_path_netshoes_ns2) else []
    files_netshoes_magalu = [os.path.join(folder_path_netshoes_magalu, f) for f in os.listdir(folder_path_netshoes_magalu) if f.endswith(('.xlsx', '.xls'))] if os.path.exists(folder_path_netshoes_magalu) else []

    # Processar Vendas
    all_vendas = []
    for file in files_vendas:
        df_vendas = processar_vendas(file)
        if not df_vendas.empty:
            all_vendas.append(df_vendas)

    if all_vendas:
        combined_vendas = pd.concat(all_vendas, ignore_index=True)
    else:
        combined_vendas = pd.DataFrame(columns=["C√ìDIGO PEDIDO", "DATA PEDIDO", "MARKETPLACE", "STATUS", "VALOR ESPERADO"])

    # Processar Centauro
    all_centauro = []
    for file in files_centauro:
        df_centauro = processar_centauro(file)
        if not df_centauro.empty:
            all_centauro.append(df_centauro)

    if all_centauro:
        combined_centauro = pd.concat(all_centauro, ignore_index=True)
    else:
        combined_centauro = pd.DataFrame(columns=["C√ìDIGO PEDIDO", "VALOR TOTAL DOS PRODUTOS"])

    # Processar Netshoes NS2
    all_netshoes_ns2 = []
    for file in files_netshoes_ns2:
        df_netshoes_ns2 = processar_netshoes_ns2(file)
        if not df_netshoes_ns2.empty:
            all_netshoes_ns2.append(df_netshoes_ns2)

    if all_netshoes_ns2:
        combined_netshoes_ns2 = pd.concat(all_netshoes_ns2, ignore_index=True)
    else:
        combined_netshoes_ns2 = pd.DataFrame(columns=["C√ìDIGO PEDIDO", "VALOR TOTAL DOS PRODUTOS", "Tipo"])

    # Processar Netshoes Magalu
    all_netshoes_magalu = []
    for file in files_netshoes_magalu:
        df_netshoes_magalu = processar_netshoes_magalu(file)
        if not df_netshoes_magalu.empty:
            all_netshoes_magalu.append(df_netshoes_magalu)

    if all_netshoes_magalu:
        combined_netshoes_magalu = pd.concat(all_netshoes_magalu, ignore_index=True)
    else:
        combined_netshoes_magalu = pd.DataFrame(columns=["C√ìDIGO PEDIDO", "VALOR TOTAL DOS PRODUTOS", "Tipo"])

    return combined_vendas, combined_centauro, combined_netshoes_ns2, combined_netshoes_magalu

# ========== EXECU√á√ÉO ==========
def main():
    # Carregar os dados automaticamente ao iniciar a aplica√ß√£o
    with st.spinner("üîÑ Carregando dados..."):
        vendas, centauro, netshoes_ns2, netshoes_magalu = carregar_dados_locais()

    if not (vendas.empty and centauro.empty and netshoes_ns2.empty and netshoes_magalu.empty):
        # Concilia√ß√£o e C√°lculos
        final_df = conciliar_e_calcular(vendas, centauro, netshoes_ns2, netshoes_magalu)
        
        # Redu√ß√£o de Colunas: Selecionar apenas as colunas essenciais
        colunas_essenciais = [
            "C√ìDIGO PEDIDO",
            "DATA PEDIDO",
            "MARKETPLACE",
            "STATUS",
            "Valor Esperado",
            "Valor Recebido",
            "Extorno",
            "Diferen√ßa",
            "Conciliado",
            "Poss√≠vel Motivo",
            "Erro de Valor",
            "Outro Erro"
        ]
        # Garantir que todas as colunas essenciais existam
        colunas_presentes = [col for col in colunas_essenciais if col in final_df.columns]
        final_df_reduzido = final_df[colunas_presentes]

        # Adicionar colunas de √≠cones para "Erro de Valor" e "Outro Erro"
        final_df_reduzido["Erro de Valor Icone"] = final_df_reduzido["Erro de Valor"]
        final_df_reduzido["Outro Erro Icone"] = final_df_reduzido["Outro Erro"]

        # Filtros na barra lateral
        st.sidebar.header("üîç Filtros")

        # Filtrar por Marketplace
        marketplaces = final_df_reduzido["MARKETPLACE"].dropna().unique().tolist()
        selected_marketplace = st.sidebar.multiselect(
            "Selecione Marketplace:", 
            marketplaces, 
            default=marketplaces
        )

        # Filtrar por Status
        status_vendas = final_df_reduzido["STATUS"].dropna().unique().tolist()
        selected_status = st.sidebar.multiselect(
            "Selecione Status da Venda:", 
            status_vendas, 
            default=status_vendas
        )

        # Slider para intervalo de valores
        valor_min = float(final_df_reduzido["Valor Esperado"].min()) if not final_df_reduzido.empty else 0.0
        valor_max = float(final_df_reduzido["Valor Esperado"].max()) if not final_df_reduzido.empty else 0.0
        valor_min_input, valor_max_input = st.sidebar.slider(
            "Intervalo de Valor Esperado:",
            min_value=0.0,
            max_value=valor_max,
            value=(valor_min, valor_max)
        )

        # Campo de pesquisa por c√≥digo do pedido
        codigo_pedido_input = st.sidebar.text_input("üîé Pesquisar por C√ìDIGO PEDIDO:")

        # Filtro por Tipo de Erro
        st.sidebar.header("‚ö†Ô∏è Filtros de Erro")
        tipos_erro = list(ERRO_MAP.keys()) + ["Divergente"]  # Adiciona "Divergente" como tipo de erro
        selected_tipo_erro = st.sidebar.multiselect(
            "Filtrar por Tipo de Erro:", 
            tipos_erro, 
            default=tipos_erro
        )

        # Checkbox para incluir/excluir sem erros
        incluir_sem_erros = st.sidebar.checkbox("üîí Incluir Pedidos sem Erros", value=True)

        # Aplicar filtros
        df_filtrado = final_df_reduzido.copy()

        if selected_marketplace:
            df_filtrado = df_filtrado[df_filtrado["MARKETPLACE"].isin(selected_marketplace)]

        if selected_status:
            df_filtrado = df_filtrado[df_filtrado["STATUS"].isin(selected_status)]

        df_filtrado = df_filtrado[
            (df_filtrado["Valor Esperado"] >= valor_min_input) &
            (df_filtrado["Valor Esperado"] <= valor_max_input)
        ]

        if codigo_pedido_input:
            df_filtrado = df_filtrado[df_filtrado["C√ìDIGO PEDIDO"].str.contains(codigo_pedido_input, case=False, na=False)]

        # Filtro por Tipo de Erro
        if selected_tipo_erro:
            conditions = []
            if "Divergente" in selected_tipo_erro:
                conditions.append(df_filtrado["Conciliado"] == "Divergente")
            if "Erro de Valor" in selected_tipo_erro:
                conditions.append(df_filtrado["Erro de Valor Icone"] == "‚ùå")
            if "Outro Erro" in selected_tipo_erro:
                conditions.append(df_filtrado["Outro Erro Icone"] == "‚ùå")
            if conditions:
                mask = conditions[0]
                for condition in conditions[1:]:
                    mask |= condition
                df_filtrado = df_filtrado[mask]

        # Filtro para incluir/excluir sem erros
        if not incluir_sem_erros:
            df_filtrado = df_filtrado[
                (df_filtrado["Erro de Valor Icone"] == "‚ùå") |
                (df_filtrado["Outro Erro Icone"] == "‚ùå") |
                (df_filtrado["Conciliado"] == "Divergente")
            ]

        # Aplicar estilos
        def highlight_errors(row):
            if row['Conciliado'] == 'Divergente':
                return ['background-color: #FFA07A'] * len(row)  # Salm√£o claro
            else:
                return [''] * len(row)

        styled_df_filtrado = df_filtrado.style.apply(highlight_errors, axis=1)

        # Layout Melhorado com Tabs
        tabs = st.tabs(["üìÑ Concilia√ß√£o", "üìà Estat√≠sticas", "üìù Log de Erros"])

        with tabs[0]:
            st.subheader("Pedidos Consolidados")
            # Exibir DataFrame com estilos
            st.dataframe(styled_df_filtrado, height=600)

            # Adicionar funcionalidade para visualizar RAW DATA
            st.markdown("### üìã RAW DATA")
            selected_pedido = st.selectbox("Selecione um C√ìDIGO PEDIDO para ver os dados brutos:", df_filtrado["C√ìDIGO PEDIDO"].unique())
            if selected_pedido:
                # Obter dados brutos de todas as fontes para o pedido selecionado
                raw_data_vendas = vendas[vendas["C√ìDIGO PEDIDO"] == selected_pedido]
                raw_data_centauro = centauro[centauro["C√ìDIGO PEDIDO"] == selected_pedido]
                raw_data_netshoes_ns2 = netshoes_ns2[netshoes_ns2["C√ìDIGO PEDIDO"] == selected_pedido]
                raw_data_netshoes_magalu = netshoes_magalu[netshoes_magalu["C√ìDIGO PEDIDO"] == selected_pedido]
                
                st.markdown("#### Vendas")
                st.dataframe(raw_data_vendas, height=200)
                
                st.markdown("#### Centauro")
                st.dataframe(raw_data_centauro, height=200)
                
                st.markdown("#### Netshoes NS2")
                st.dataframe(raw_data_netshoes_ns2, height=200)
                
                st.markdown("#### Netshoes Magalu")
                st.dataframe(raw_data_netshoes_magalu, height=200)

            # Legenda
            st.markdown("### üóíÔ∏è Legenda")
            st.markdown("‚úÖ **OK**: Conciliado sem diverg√™ncias.")
            st.markdown("‚ùå **Divergente**: H√° diverg√™ncias nos dados.")
            st.markdown("‚ùå **Erro de Valor**: Discrep√¢ncia no valor.")
            st.markdown("‚ùå **Outro Erro**: H√° outros erros.")

        with tabs[1]:
            st.subheader("üìä Estat√≠sticas")
            col_a, col_b, col_c, col_d = st.columns(4)
            with col_a:
                st.metric("Total de Pedidos", len(final_df_reduzido))
            with col_b:
                st.metric("Pedidos Conciliados", len(final_df_reduzido[final_df_reduzido['Conciliado'] == "OK"]))
            with col_c:
                st.metric("Pedidos Divergentes", len(final_df_reduzido[final_df_reduzido['Conciliado'] == "Divergente"]))
            with col_d:
                st.metric("Total Extornos", final_df_reduzido["Extorno"].sum())

            # Gr√°fico de Distribui√ß√£o de Erros
            st.subheader("üìâ Distribui√ß√£o de Erros")
            erro_counts = final_df_reduzido["Conciliado"].value_counts().reset_index()
            erro_counts.columns = ["Conciliado", "Quantidade"]
            st.bar_chart(erro_counts.set_index("Conciliado"))

        with tabs[2]:
            st.subheader("üìù Log de Erros")
            
            # Convertendo lista de erros para DataFrame
            if st.session_state.lista_erros:
                log_erros_df = pd.DataFrame(st.session_state.lista_erros)
                
                # Mapeamento de c√≥digos de erro para descri√ß√£o
                log_erros_df["Descricao_Erro"] = log_erros_df["Codigo_Erro"].map({
                    1001: "Erro ao ler o arquivo",
                    1002: "Erro na convers√£o de tipo de dados",
                    1003: "Valor nulo inesperado",
                    1004: "Diverg√™ncia encontrada",
                    1005: "Falha na consolida√ß√£o dos dados"
                }).fillna("Erro desconhecido")
                
                # Filtro para tipos de erro
                tipos_erro_log = list(ERRO_MAP.keys())
                selected_tipo_erro_log = st.multiselect(
                    "üîç Filtrar por Tipo de Erro:", 
                    tipos_erro_log, 
                    default=tipos_erro_log
                )
                
                # Filtrar o log de erros
                if selected_tipo_erro_log:
                    codigos_filtrados = [ERRO_MAP[tipo] for tipo in selected_tipo_erro_log]
                    df_log_filtrado = log_erros_df[log_erros_df["Codigo_Erro"].isin(codigos_filtrados)]
                else:
                    df_log_filtrado = log_erros_df.copy()
                
                if not df_log_filtrado.empty:
                    # Reordenar colunas para melhor visualiza√ß√£o
                    df_log_filtrado = df_log_filtrado[["Timestamp", "Arquivo", "Codigo_Erro", "Descricao_Erro", "Mensagem_Erro"]]
                    
                    # Exibir DataFrame de log de erros
                    st.dataframe(df_log_filtrado, height=300)
                else:
                    st.write("Nenhum erro registrado para os tipos selecionados.")
            else:
                st.write("Nenhum erro registrado.")

        # Bot√£o para baixar a planilha consolidada
        st.sidebar.header("üíæ Download")
        st.sidebar.download_button(
            label="üì• Baixar Planilha Consolidada",
            data=final_df_reduzido.to_csv(index=False).encode('utf-8'),
            file_name='consolidado_repasses_vendas.csv',
            mime='text/csv'
        )
    else:
        st.info("üìÅ Certifique-se de que as pastas estejam corretamente organizadas e contenham os arquivos necess√°rios.")
        st.markdown("""
        **Estrutura de Diret√≥rios Esperada:**
        
        ```
        /seu_diretorio_projeto/
        ‚îÇ
        ‚îú‚îÄ‚îÄ trilha.py
        ‚îú‚îÄ‚îÄ Vendas/
        ‚îÇ   ‚îú‚îÄ‚îÄ arquivo1.xlsx
        ‚îÇ   ‚îú‚îÄ‚îÄ arquivo2.xlsx
        ‚îÇ   ‚îî‚îÄ‚îÄ ...
        ‚îú‚îÄ‚îÄ Repasse Centauro/
        ‚îÇ   ‚îú‚îÄ‚îÄ arquivo1.csv
        ‚îÇ   ‚îú‚îÄ‚îÄ arquivo2.csv
        ‚îÇ   ‚îî‚îÄ‚îÄ ...
        ‚îú‚îÄ‚îÄ Repasse Netshoes/
        ‚îÇ   ‚îú‚îÄ‚îÄ NS2/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arquivo1.xlsx
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ arquivo2.xlsx
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
        ‚îÇ   ‚îî‚îÄ‚îÄ Magalu Pagamentos/
        ‚îÇ       ‚îú‚îÄ‚îÄ arquivo1.xlsx
        ‚îÇ       ‚îú‚îÄ‚îÄ arquivo2.xlsx
        ‚îÇ       ‚îî‚îÄ‚îÄ ...
        ```
        
        **Observa√ß√µes:**
        - Verifique se os nomes das colunas nos arquivos correspondem exatamente aos utilizados no script.
        - Certifique-se de que os arquivos estejam no formato correto (XLSX, XLS para Excel e CSV para Centauro).
        """)

if __name__ == "__main__":
    main()
